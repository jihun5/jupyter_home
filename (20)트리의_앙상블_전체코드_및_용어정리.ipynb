{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPigSDBEPehRzRUOKhlcIWv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihun5/jupyter_home/blob/main/(20)%ED%8A%B8%EB%A6%AC%EC%9D%98_%EC%95%99%EC%83%81%EB%B8%94_%EC%A0%84%EC%B2%B4%EC%BD%94%EB%93%9C_%EB%B0%8F_%EC%9A%A9%EC%96%B4%EC%A0%95%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U89hK4193Aui",
        "outputId": "b3428612-5d89-4852-fa6f-e5086081b781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9973541965122431 0.8905151032797809\n",
            "[0.23167441 0.50039841 0.26792718]\n",
            "0.8934000384837406\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "train_input, test_input, train_target, test_target = train_test_split(data, target, random_state=42, test_size=0.2)\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.feature_importances_)\n",
        "\n",
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
        "\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.oob_score_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "\n",
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evj61nEPAJuA",
        "outputId": "92192de3-c3e3-4688-d5e8-6a49e1385af3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9974503966084433 0.8887848893166506\n",
            "[0.20183568 0.52242907 0.27573525]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "\n",
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXaPOws0A-xJ",
        "outputId": "cd69c9d1-d286-4c75-ebd8-f00e45602cc9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n",
            "[0.20183568 0.52242907 0.27573525]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "\n",
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "gb.fit(train_input, train_target)\n",
        "print(gb.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcN0Rw7SBiu2",
        "outputId": "3780bb73-ff28-4251-e723-887853ecbfbe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n",
            "0.9464595437171814 0.8780082549788999\n",
            "[0.15872278 0.68010884 0.16116839]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "\n",
        "hgb.fit(train_input, train_target)\n",
        "print(rf.feature_importances_)\n",
        "hgb.score(test_input, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk-qs_fEDBEA",
        "outputId": "ea5203dd-57aa-4eea-9036-4a6b30ef62a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9321723946453317 0.8801241948619236\n",
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8723076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
        "scpres = cross_validate(xgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pmmE1DAD6mg",
        "outputId": "0032a66f-1562-4075-87dc-f6f63568b30c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgb = LGBMClassifier(random_state=42)\n",
        "scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZH7GT4cFDug",
        "outputId": "9de565bb-acb1-468b-e60b-d00ac5564fab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.935828414851749 0.8801251203079884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앙상블 학습은 더 좋은 예측 결과를 만들기 위해 여러 개의 모델을 훈련하는 머신러닝 알고리즘\n",
        "\n",
        "랜덤 포레스트는 대표적인 결정 트리 기반의 앙상블 학습 방법, 부트스트랩 샘플을 사용하고 랜덤하게 일부 특성을 선택하여 트리를 만드는 것이 특징\n",
        "\n",
        "엑스트라 트리는 랜덤 포레스트와 비슷하게 결정 트리를 사용하여 앙상블 모델을 만들지만 부트스트랩 샘플을 사용하지 않음, 대신 랜덤하게 노드를 분할해 과대적합을 감소시킴\n",
        "\n",
        "그레디언트 부스팅은 랜덤 포레스트나 엑스트라 트리와 달리 결정 트리를 연속적으로 추가하여 손실 함수를 최소화하는 앙상블 방법입니다. 이런 이유로 훈련 속도가 조금 느리지만 더 좋은 성능을 기대할 수 있다.\n",
        "\n",
        "그레디언트 부스팅의 속도를 개선한 것이 히스토그램 기반 그레이디언트 부스팅이며 안정적인 결과와 높은 성능으로 인기가 높다."
      ],
      "metadata": {
        "id": "9ZywbAEfFjsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomForestClassifier는 랜덤 포레스트 분류 클래스다.\n",
        "n_esimators 매개변수는 앙상블을 구성할 트리의 개수를 지정한다. 기본값은 100이다.\n",
        "criterion 매개변수는 불순도를 지정하며 기본값은 지니불순도를 의미하는 gini이고 entropy를 선택하여 엔트로피 불순도를 사용할 수 있다.\n",
        "max_depth는 트리가 성장할 최대 깊이를 지정한다. 기본값은 None으로 지정하면 리프 노드가 순수하거나 min_samples_split보다 샘플 개수가 적을 때까지 성장합니다.\n",
        "min_samples_split은 노드를 나누기 위한 최소 샘플 개수다. 기본값은 2다.\n",
        "max_features 매개변수는 최적의 분할을 위해 탐색할 특성의 개수를 지정한다. 기본값은 auto로 특성개수의 제곱근이다.\n",
        "bootstrap 매개변수는 부트스트랩 샘플을 사용할지 지정한다. 기본값은 True다. oob_score는 OOB샘플을 사용하여 훈련한 모델을 평가할지 지정한다. 기본값은 False다. n-jobs 매개변수는 병렬 실행에 사용할 CPU코어 수를 지정한다. 기본값은 1로 하나의 코어를 사용한다. -1로 지정하면 시스템에 있는 모든 코어를 사용한다.\n",
        "\n",
        "ExtraTreeClassifier는 n_esimators,criterion,max_depth, min_samples_split, max_features 매개변수는 랜덤 포레스트와 동일하다. bootstrap 매개 변수는 부트스트랩 샘플을 사용할 지 지정한다. 기본값은 False다. oob_score는 OOB샘플을 사용하여 훈련한 모델을 평가할지 지정한다. 기본값은 False다.\n",
        "n_jobs매개변수는 병렬 실행에 사용할 CPU코어 수를 지정한다. 기본값은 1로 하나의 코어를 사용한다. -1로 지정하면 시스템에 있는 모든 코어를 사용한다."
      ],
      "metadata": {
        "id": "qcoQnr2sV_ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GradientBosstingClassifier에 loss 매개변수는 손실 함수를 지정한다. 기본값은 로지스틱 손실 함수를 의미하는 deviance다. learning_rate 매개변수는 트리가 앙상블에 기여하는 정도를 조절한다. 기본값은 0.1이다.\n",
        "n_estimators매개변수는 부스팅 단계를 수행하는 트리의 개수입니다. 기본값은 100이다. subsample매개변수는 사용할 훈련 세트의 샘플 비율을 지정한다. 기본값은 1.0이다.\n",
        "max_depth 매개변수는 개별 회귀 트리의 최대깊이다. 기본값은 3이다.\n",
        "\n",
        "HistGradientBoostingClassifier은 learning_rate 매개변수는 학습률 또는 감쇠율이라고 한다. 기본값은 0.1이며, 1.0이면 감쇠가 전혀 없다.\n",
        "max_iter은 부스팅 단계를 수행하는 트리의 개수로 기본값은 100이다.\n",
        "max_bins는 입력 데이터를 나눌 구간의 개수로, 기본값은 255이며 이보다 크게 지정할 수 없다."
      ],
      "metadata": {
        "id": "5Auw_vb3XoSr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wjgO3OV7FbMO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}